{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49bbb2a6-fe37-4c59-888a-11e4dde017bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import queue\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from BPC_TSP_Classes import *\n",
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "DATA_JSON = \"graphs_lower_dims.json\"\n",
    "\n",
    "# import pyspark\n",
    "\n",
    "# number_cores = 8\n",
    "# memory_gb = 24\n",
    "# conf = (\n",
    "#     pyspark.SparkConf()\n",
    "#         .setMaster('local[{}]'.format(number_cores))\n",
    "#         .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    "# )\n",
    "# sc = pyspark.SparkContext(conf=conf)\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"BPC_TSP\") \\\n",
    "    .config(\"spark.executor.instances\", 4) \\\n",
    "    .config(\"spark.executor.cores\", 4) \\\n",
    "    .master('local') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b046395b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SearchNode' object has no attribute 'profit_earned'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18416\\1596848645.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;31m# Plotter.plot(graphs, solved_brute_force, solved_minbound)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18416\\1596848645.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[0mtester\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTester\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m     \u001b[0msolved_minbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtester\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminbound_evaluate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m     \u001b[0mPlotter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolved_minbound\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[0mTester\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_all_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolved_minbound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"solved_minbound.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18416\\1596848645.py\u001b[0m in \u001b[0;36msolve_all\u001b[1;34m(self, boundfunc)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msolve_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve_graph_with_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msolve_graph_with_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18416\\1596848645.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msolve_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve_graph_with_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msolve_graph_with_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18416\\1596848645.py\u001b[0m in \u001b[0;36msolve_graph_with_metrics\u001b[1;34m(self, graph, boundfunc)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBranchBoundSolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0msolution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Solved graph with {graph.dim} nodes.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18416\\1596848645.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(self, start_node)\u001b[0m\n\u001b[0;32m    118\u001b[0m                               \u001b[0mremaining_capacity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                               reduced_graph=(self._graph, {}))\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_profit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfirst_sn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofit_earned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_sn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# Calculate bound based upon root and graph, and add to search node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SearchNode' object has no attribute 'profit_earned'"
     ]
    }
   ],
   "source": [
    "class SearchNodeQueue:\n",
    "    def __init__(self):\n",
    "        self._q = queue.PriorityQueue()\n",
    "    \n",
    "    def push(self, node):\n",
    "        self._q.put((-node.bound, node))\n",
    "    \n",
    "    def pop(self):\n",
    "        return self._q.get()[1]\n",
    "    \n",
    "    def empty(self):\n",
    "        return self._q.empty()\n",
    "\n",
    "class BBHelpers:\n",
    "    @staticmethod\n",
    "    def build_new_sn(prev_sn, t, bound_finder):\n",
    "        new_vertex = t[0]\n",
    "        new_capacity = prev_sn.capacity - t[1]\n",
    "        prof_if_unvisited = t[2]\n",
    "        new_visited = prev_sn.visited.copy()\n",
    "        \n",
    "        # NOTE: Probably doesn't need to be conditional anymore, as adjacent-node finder no longer considers visited\n",
    "        if new_vertex in prev_sn.visited:\n",
    "            new_profit = prev_sn.profit\n",
    "        else:\n",
    "            new_profit = prev_sn.profit + prof_if_unvisited\n",
    "            new_visited.add(new_vertex)\n",
    "        \n",
    "        r = prev_sn.reduced_graph[0].get_reduced(prev_sn.vertex, prev_sn.reduced_graph[1], prev_sn.visited)\n",
    "        \n",
    "        new_path = prev_sn.path[:]\n",
    "        if (prev_sn.vertex, new_vertex) in r[1]:\n",
    "            new_path += r[1][(prev_sn.vertex, new_vertex)] + [new_vertex]\n",
    "        else:\n",
    "            new_path += [new_vertex]\n",
    "        \n",
    "        new_sn = SearchNode(vert=new_vertex,\n",
    "                   path=new_path,\n",
    "                   visited=new_visited,\n",
    "                   profit_earned=new_profit,\n",
    "                   remaining_capacity=new_capacity,\n",
    "                   reduced_graph=r)\n",
    "        new_sn.set_bound( bound_finder(r, new_sn) )\n",
    "        return new_sn\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_search_node(sn_dat):\n",
    "        (g, best_prof, sn, bound_finder) = sn_dat # Get named vars from passed tuple\n",
    "        if sn.reduced_graph is None: # If root, just use main graph\n",
    "            graph = g\n",
    "        else: # Otherwise use reduced graph\n",
    "            graph = sn.reduced_graph\n",
    "        adj = graph[0].get_all_adjacent(sn.vertex, sn.visited) # Get data on all adjacent nodes (id, length of edge to the node, weight of the node) that have not yet been visited\n",
    "        almost = [BBHelpers.build_new_sn(sn, x, bound_finder) for x in adj if x[1] <= sn.capacity] # Generate new search nodes, so long as new traversal does not go over capacity\n",
    "        return [s for s in almost if s.bound > best_prof] # Filter out unpromising nodes\n",
    "    \n",
    "    \n",
    "        \n",
    "class BranchBoundSolver:\n",
    "    def __init__(self, graph, num_threads, boundFunc):\n",
    "        self._graph = graph\n",
    "        self._num_threads = num_threads\n",
    "        self.find_bound = boundFunc\n",
    "        self._q = SearchNodeQueue()\n",
    "        self.best_profit = 0\n",
    "        self.best_path = []\n",
    "        self.bound_data = None\n",
    "    \n",
    "    def pull_search_nodes(self):\n",
    "        accum = [] # Will receive new search nodes, and then be parallelized\n",
    "        nt = self._num_threads\n",
    "        while not self._q.empty() and nt > 0:\n",
    "            # Tuple members are: (The whole graph, the best found profit, the current node, the bound finding function, legacy; no longer used)\n",
    "            accum.append( (self._graph, self.best_profit, self._q.pop(), self.find_bound) )# , self.bound_data) )\n",
    "            nt -= 1\n",
    "        return spark.sparkContext.parallelize(accum)\n",
    "    \n",
    "        \n",
    "    \n",
    "#     def solve(self, start_node):\n",
    "#         first_sn = SearchNode(vert=start_node,\n",
    "#                               path=[start_node],\n",
    "#                               visited={start_node},\n",
    "#                               profit_earned=self._graph.vert_weights[start_node],\n",
    "#                               remaining_capacity=self._graph.limit)\n",
    "#         self.bound_data = self.find_bound.setup(self._graph, first_sn)\n",
    "        \n",
    "#         first_sn.set_bound( self.find_bound.evaluate(self.bound_data, first_sn) )\n",
    "#         best_possible = first_sn.bound\n",
    "#         self._q.push(first_sn)\n",
    "        \n",
    "#         while not self._q.empty():\n",
    "#             sns = self.pull_search_nodes()\n",
    "#             new_sns = sns.flatMap(lambda x : BBHelpers.process_search_node(x))\n",
    "#             new_best_candidate = new_sns.map(\n",
    "#                 lambda s : (s.profit, s.path)\n",
    "#             ).fold((0, []), lambda x, y : max(x, y, key=lambda t : t[0]))\n",
    "            \n",
    "#             if new_best_candidate[0] > self.best_profit:\n",
    "#                 (self.best_profit, self.best_path) = new_best_candidate\n",
    "#             if new_best_candidate[0] == best_possible:\n",
    "#                 break\n",
    "                \n",
    "#             new_sns_arr = new_sns.collect()\n",
    "#             for x in new_sns_arr:\n",
    "#                 self._q.push(x)\n",
    "#         return (self.best_profit, self.best_path)\n",
    "\n",
    "    def solve(self, start_node):\n",
    "        # Create root search node at starting vertex\n",
    "        \n",
    "        # Note: We don't need to remove visited node until we have left it, as we want access to its connected-node data.\n",
    "        \n",
    "        first_sn = SearchNode(vert=start_node,\n",
    "                              path=[start_node],\n",
    "                              visited={start_node},\n",
    "                              profit_earned=self._graph.vert_weights[start_node],\n",
    "                              remaining_capacity=self._graph.limit,\n",
    "                              reduced_graph=(self._graph, {}))\n",
    "        (self.best_profit, self.best_path) = (first_sn.profit, first_sn.path)\n",
    "        \n",
    "        # Calculate bound based upon root and graph, and add to search node\n",
    "        first_sn.set_bound( self.find_bound(self._graph, first_sn) )\n",
    "        # Save root bound as best possible profit\n",
    "        all_verts_sum = sum(self._graph.vert_weights)\n",
    "        root_bound = first_sn.bound\n",
    "        # Push initial search node into priority queue\n",
    "        self._q.push(first_sn)\n",
    "\n",
    "        # Loop continuously pops search nodes off queue, calculates new states (nodes) from them, and loads those new nodes back into queue.\n",
    "        # Ends when there are no more nodes to process\n",
    "        while not self._q.empty():\n",
    "            sns = self.pull_search_nodes() # Pull several search nodes off of the queue (also attaching metadata to them) to be processed in parallel\n",
    "            new_sns = sns.flatMap(lambda x : BBHelpers.process_search_node(x)) # Calculate new search nodes from current\n",
    "            new_best_candidate = new_sns.map(\n",
    "                lambda s : (s.profit, s.path)\n",
    "            ).fold((0, []), lambda x, y : max(x, y, key=lambda t : t[0])) # Find best profit and associated path from calculated search node\n",
    "            # If best profit from batch is greater than overall best profit, replace overall with this new best profit\n",
    "            if new_best_candidate[0] > self.best_profit:\n",
    "                (self.best_profit, self.best_path) = new_best_candidate\n",
    "            \n",
    "            # If best profit from batch is as great as the calculated best possible, then we can't do any better, so we're done.\n",
    "            if new_best_candidate[0] == root_bound or new_best_candidate[0] == all_verts_sum:\n",
    "                break\n",
    "        \n",
    "            # Push all new search nodes into the queue\n",
    "            new_sns_arr = new_sns.collect()\n",
    "            for x in new_sns_arr:\n",
    "                self._q.push(x)\n",
    "            \n",
    "        # Once we know we can't do any better, return best found profit and associated path\n",
    "        return (self.best_profit, self.best_path)\n",
    "    \n",
    "# Namespace\n",
    "class DataSetup:\n",
    "    @staticmethod\n",
    "    def build_from_csvs(data):\n",
    "        f = lambda x : math.inf if x == 'i' else int(x)\n",
    "        acc = []\n",
    "        dim = None\n",
    "\n",
    "        with open(data['edge_w'], newline='') as edges_file:\n",
    "            read_edges = csv.reader(edges_file)\n",
    "            for row in read_edges:\n",
    "                if dim == None:\n",
    "                    dim = len(row)\n",
    "                acc += [f(x) for x in row]\n",
    "        grid = SquareMat(acc, dim)\n",
    "\n",
    "        acc = []\n",
    "\n",
    "        vert_weights = None\n",
    "        with open(data['vert_w'], newline='') as verts_file:\n",
    "            read_verts = csv.reader(verts_file)\n",
    "            for row in read_verts:\n",
    "                vert_weights = list( map(lambda x : int(x), row) )\n",
    "        return BPC_TSP_Graph(grid, dim, vert_weights, data['lim'])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_from_random(data):\n",
    "        num_generations = data['num_generations']\n",
    "        acc = []\n",
    "        for i in range(num_generations):\n",
    "            acc.append(DataSetup.build_single_from_random(data))\n",
    "\n",
    "        return acc\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_single_from_random(data):\n",
    "        grid_size = data['num_verts'] ** 2\n",
    "        g_raw = [None for _ in range(grid_size)]\n",
    "        percent_unconnected = data['percent_unconnected']\n",
    "        for i in range(grid_size):\n",
    "            if random.randrange(101) < percent_unconnected:\n",
    "                g_raw[i] = math.inf\n",
    "            else:\n",
    "                g_raw[i] = random.randrange(1, data['max_edge_weight'] + 1)\n",
    "\n",
    "\n",
    "        for i in range(data['num_verts']):\n",
    "            g_raw[i * data['num_verts'] + i] = 0\n",
    "        \n",
    "        g = SquareMat(g_raw, data['num_verts'])\n",
    "\n",
    "        w = [random.randrange(1, data['max_vert_weight'] + 1) for _ in range(g.dim)]\n",
    "\n",
    "        mintotal = 0\n",
    "        for row in range(data['num_verts']):\n",
    "            mintotal += min(g.get_col(row))\n",
    "\n",
    "        cap_policy = data['cap_range']['policy']\n",
    "\n",
    "        cap = None\n",
    "        if cap_policy == 'minsum':\n",
    "            cap = DataSetup.capacity_from_minsum(data['cap_range']['attrs'], g, data['num_verts'])\n",
    "        elif cap_policy == 'absolute':\n",
    "            cap = DataSetup.capacity_from_absolute(data['cap_range']['attrs'])\n",
    "        else:\n",
    "            raise ValueError(\"Uh oh, spaghettio!\")\n",
    "\n",
    "        # debug_log(f\"Built:\\n{str(g)}\\n\")\n",
    "        return BPC_TSP_Graph(g, data['num_verts'], w, cap)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def capacity_from_absolute(attrs):\n",
    "        return random.randrange(attrs['lower'], attrs['upper'])\n",
    "\n",
    "    @staticmethod\n",
    "    def capacity_from_minsum(cap_attrs, g, num_verts):\n",
    "        mintotal = 0\n",
    "        for row in range(g.dim):\n",
    "            c_row = [n for n in g.get_col(row) if n > 0]\n",
    "            row_min = min(c_row)\n",
    "            mintotal += row_min if not math.isinf(row_min) else 0\n",
    "\n",
    "        lower = mintotal * cap_attrs['lower_multiplier']\n",
    "        upper = mintotal * cap_attrs['upper_multiplier']\n",
    "        lower = int(lower)\n",
    "        upper = int(upper)\n",
    "\n",
    "        return random.randrange(lower, upper)\n",
    "\n",
    "    def build_graphs(data):\n",
    "        acc = []\n",
    "        for d in data['file_defined']:\n",
    "            acc.append(DataSetup.build_from_csvs(d))\n",
    "\n",
    "        for d in data['randomized']:\n",
    "            acc += DataSetup.build_from_random(d)\n",
    "\n",
    "        return acc\n",
    "    \n",
    "class Tester:\n",
    "    def __init__(self, graphs):\n",
    "        self.graphs = graphs\n",
    "    \n",
    "    def solve_all(self, boundfunc):\n",
    "        return [self.solve_graph_with_metrics(g, boundfunc) for g in self.graphs]\n",
    "    \n",
    "    def solve_graph_with_metrics(self, graph, boundfunc):\n",
    "        solver = BranchBoundSolver(graph, 16, boundfunc)\n",
    "        t = time.time()\n",
    "        solution = solver.solve(0)\n",
    "        t = time.time() - t\n",
    "        print(f\"Solved graph with {graph.dim} nodes.\")\n",
    "        return (solution, t)\n",
    "    \n",
    "    @staticmethod\n",
    "    def is2pow(n):\n",
    "        return (n & (n - 1) == 0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def print_some_results(graphs, solved):\n",
    "        for idx, result in enumerate(solved):\n",
    "            (solution, t) = result\n",
    "            if Tester.is2pow(idx + 1):\n",
    "                Tester.print_result(graphs[idx], result, idx + 1)\n",
    "                \n",
    "    @staticmethod\n",
    "    def print_result(g, r, idx):\n",
    "        print(f\"{idx}:\")\n",
    "        for i in range(g.dim):\n",
    "            row = g.grid.get_row(i)\n",
    "            row = map(lambda x : str(x), row)\n",
    "            row = \"\\t\".join(row)\n",
    "            print(row)\n",
    "        print(f\"Profit: {r[0][0]}\")\n",
    "        print(f\"Path: {r[0][1]}\\n\")\n",
    "        print(f\"Calculation Time: {r[1]}\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def make_result_string(g, r, idx):\n",
    "        acc = \"\"\n",
    "        acc += f\"{idx}:\\n\"\n",
    "        acc += str(g.grid) + \"\\n\\n\"\n",
    "        joined = '\\t'.join([str(v) for v in g.vert_weights])\n",
    "        acc += f\"Vertex Weights:\\n{joined}\\n\"\n",
    "        acc += f\"Capacity: {g.limit}\\n\\n\"\n",
    "        acc += f\"Profit: {r[0][0]}\\n\"\n",
    "        acc += f\"Path: {r[0][1]}\\n\"\n",
    "        acc += f\"Calculation Time: {r[1]}\\n\\n\\n\"\n",
    "        return acc\n",
    "    \n",
    "    @staticmethod\n",
    "    def output_all_results(graphs, solved, outfile):\n",
    "        open(outfile, \"w\").close()\n",
    "        with open(outfile, \"a\") as f:\n",
    "            for idx, result in enumerate(solved):\n",
    "                (solution, t) = result\n",
    "                rstr = Tester.make_result_string(graphs[idx], result, idx + 1)\n",
    "                f.write(rstr)\n",
    "        \n",
    "        \n",
    "class Plotter:\n",
    "    @staticmethod\n",
    "    def key_reduce(pairs):\n",
    "        acc = {}\n",
    "        for pair in pairs:\n",
    "            if pair[0] not in acc:\n",
    "                acc[pair[0]] = (pair[1], 1) # (time taken, 1)\n",
    "            else:\n",
    "                vals_at_key = acc[pair[0]]\n",
    "                acc[pair[0]] = (vals_at_key[0] + pair[1], vals_at_key[1] + 1)\n",
    "        \n",
    "        # Now acc[pair[0]] == (sum of times taken, amount of times taken)\n",
    "        return [(k, p[0] / p[1]) for k, p in acc.items()] # Return list of (amount of vertices, average time taken for this amount)\n",
    "    \n",
    "    @staticmethod\n",
    "    def print_average_times(times):\n",
    "        for i, _ in enumerate(times[0]):\n",
    "            print(f\"Average time for {times[0][i]} nodes:\\t{times[1][i]} seconds\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot(graphs, results):\n",
    "        times = [x[1] for x in results]\n",
    "        node_amounts = [x.dim for x in graphs]\n",
    "        \n",
    "        zip_times = list(zip(node_amounts, times))\n",
    "        reduce_times = Plotter.key_reduce(zip_times)\n",
    "        \n",
    "        unzip_times = zip(*reduce_times)\n",
    "        processed_times = [list(x) for x in unzip_times]\n",
    "        \n",
    "        Plotter.print_average_times(processed_times)\n",
    "        plt.plot(processed_times[0], processed_times[1])\n",
    "        plt.ylabel('Average time')\n",
    "        plt.xlabel('Number of vertices')\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        \n",
    "    \n",
    "#     @staticmethod\n",
    "#     def plot(graphs, brute_force_results, minsums_results):\n",
    "#         # Result-object: (solution, time-taken)\n",
    "#         # Results-object: [Result-object_a, Result-object_b, ...]\n",
    "#         bftimes = [x[1] for x in brute_force_results] # Get times for brute-force results\n",
    "#         mstimes = [x[1] for x in minsums_results] # Get times for minsums results\n",
    "#         node_amounts = [x.dim for x in graphs] # Get numbers of nodes for each graph\n",
    "        \n",
    "#         z_bft = list(zip(node_amounts, bftimes)) # [(node_ammount1, brute_force_time1), (node_ammount2, brute_force_time2), ...]\n",
    "#         r_bft = Plotter.key_reduce(z_bft) # Reduce by key to take average of all times for each number of nodes\n",
    "#         unzipped_bft = zip(*r_bft)\n",
    "#         done_bft = [list(x) for x in unzipped_bft]\n",
    "        \n",
    "#         z_mst = list(zip(node_amounts, mstimes))\n",
    "#         r_mst = Plotter.key_reduce(z_mst)\n",
    "#         unzipped_mst = zip(*r_mst)\n",
    "#         done_mst = [list(x) for x in unzipped_mst]\n",
    "        \n",
    "#         # Brute Force\n",
    "#         plt.plot(done_bft[1], done_bft[0])\n",
    "#         plt.ylabel('Average time')\n",
    "#         plt.xlabel('Number of vertices')\n",
    "#         plt.show()\n",
    "        \n",
    "#         # Minsums\n",
    "#         plt.plot(done_mst[1], done_mst[0])\n",
    "#         plt.ylabel('Average time')\n",
    "#         plt.xlabel('Number of vertices')\n",
    "#         plt.show()\n",
    "            \n",
    "\n",
    "def main():\n",
    "    clear_debug_log()\n",
    "    data = None\n",
    "    with open(DATA_JSON) as j: \n",
    "        data = json.load(j)\n",
    "    \n",
    "    graphs = DataSetup.build_graphs(data)\n",
    "        \n",
    "    \n",
    "    tester = Tester(graphs)\n",
    "    \n",
    "    solved_minbound = tester.solve_all(minbound_evaluate)\n",
    "    Plotter.plot(graphs, solved_minbound)\n",
    "    Tester.output_all_results(graphs, solved_minbound, \"solved_minbound.txt\")\n",
    "    \n",
    "    solved_brute_force = tester.solve_all(brute_force_evaluate)\n",
    "    Plotter.plot(graphs, solved_brute_force)\n",
    "    Tester.output_all_results(graphs, solved_brute_force, \"solved_brute_force.txt\")\n",
    "    \n",
    "    Tester.print_some_results(graphs, solved_minbound)\n",
    "    Tester.print_some_results(graphs, solved_brute_force)\n",
    "    \n",
    "    # Plotter.plot(graphs, solved_brute_force, solved_minbound)\n",
    "\n",
    "main()    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c441e13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
